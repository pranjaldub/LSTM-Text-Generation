{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__  import print_function\n",
    "from builtins import range,input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string,numpy as np,pandas as pd,matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding,Input,LSTM,Dropout,Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD,RMSprop,Adam\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 2000\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 12\n",
      "Found 3056 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#prepare input , target , and load data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for line in open('robert_frost.txt'):\n",
    "  line = line.rstrip()\n",
    "  if not line:\n",
    "    continue\n",
    "\n",
    "  input_line = '<sos> ' + line\n",
    "  target_line = line + ' <eos>'\n",
    "\n",
    "  input_texts.append(input_line)\n",
    "  target_texts.append(target_line)\n",
    "\n",
    "\n",
    "all_lines = input_texts + target_texts\n",
    "\n",
    "# convert the sentences (strings) into integers\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer.fit_on_texts(all_lines)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "# find max seq length\n",
    "max_sequence_length_from_data = max(len(s) for s in input_sequences)\n",
    "print('Max sequence length:', max_sequence_length_from_data)\n",
    "\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))\n",
    "assert('<sos>' in word2idx)\n",
    "assert('<eos>' in word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1436, 12)\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "max_sequence_length = min(max_sequence_length_from_data, MAX_SEQUENCE_LENGTH)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n",
    "print('Shape of data tensor:', input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B.%sd.txt' %100)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot the targets (can't use sparse cross-entropy)\n",
    "one_hot_targets = np.zeros((len(input_sequences), max_sequence_length, num_words))\n",
    "for i, target_sequence in enumerate(target_sequences):\n",
    "  for t, word in enumerate(target_sequence):\n",
    "    if word > 0:\n",
    "      one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  # trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function keras.engine.network.Network.summary(self, line_length=None, positions=None, print_fn=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Building model...')\n",
    "\n",
    "# create an LSTM network with a single LSTM\n",
    "input_ = Input(shape=(max_sequence_length,))\n",
    "initial_h = Input(shape=(LATENT_DIM,))\n",
    "initial_c = Input(shape=(LATENT_DIM,))\n",
    "x = embedding_layer(input_)\n",
    "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "x, _, _ = lstm(x, initial_state=[initial_h, initial_c])\n",
    "# don't need the states here\n",
    "dense = Dense(num_words, activation='softmax')\n",
    "output = dense(x)\n",
    "\n",
    "model = Model([input_, initial_h, initial_c], output)\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "   #optimizer='rmsprop',\n",
    "  #optimizer=SGD(lr=0.01),\n",
    "  optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "Model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing callbacks\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(\"poem_rnn_3_layers.h5\",\n",
    "                            monitor=\"loss\",\n",
    "                            mode=\"min\",\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"loss\",\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\",\n",
    "                             factor=0.1,\n",
    "                             patience=2,\n",
    "                             verbose=1,\n",
    "                             min_delta=0.0001)\n",
    "#putting callbacks in callbacks list\n",
    "callbacks = [checkpoint,early_stopping,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "WARNING:tensorflow:From /home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/pranjaldub1999/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1292 samples, validate on 144 samples\n",
      "Epoch 1/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 5.6213 - accuracy: 0.0101 - val_loss: 6.0583 - val_accuracy: 0.0770\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.62126, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 2/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.6006 - accuracy: 0.0819 - val_loss: 6.0323 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00002: loss improved from 5.62126 to 5.60061, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 3/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.5697 - accuracy: 0.0833 - val_loss: 5.9990 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00003: loss improved from 5.60061 to 5.56973, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 4/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.5313 - accuracy: 0.0833 - val_loss: 5.9577 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00004: loss improved from 5.56973 to 5.53131, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 5/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.4833 - accuracy: 0.0833 - val_loss: 5.9051 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00005: loss improved from 5.53131 to 5.48333, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 6/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.4223 - accuracy: 0.0833 - val_loss: 5.8381 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00006: loss improved from 5.48333 to 5.42235, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 7/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.3452 - accuracy: 0.0833 - val_loss: 5.7534 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00007: loss improved from 5.42235 to 5.34520, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 8/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.2509 - accuracy: 0.0833 - val_loss: 5.6546 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00008: loss improved from 5.34520 to 5.25089, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 9/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.1508 - accuracy: 0.0833 - val_loss: 5.5678 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00009: loss improved from 5.25089 to 5.15078, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 10/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.0833 - accuracy: 0.0833 - val_loss: 5.5316 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00010: loss improved from 5.15078 to 5.08330, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 11/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.0557 - accuracy: 0.0833 - val_loss: 5.5050 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00011: loss improved from 5.08330 to 5.05568, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 12/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 5.0254 - accuracy: 0.0833 - val_loss: 5.4753 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00012: loss improved from 5.05568 to 5.02543, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 13/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.9965 - accuracy: 0.0833 - val_loss: 5.4485 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00013: loss improved from 5.02543 to 4.99654, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 14/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.9691 - accuracy: 0.0833 - val_loss: 5.4221 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00014: loss improved from 4.99654 to 4.96913, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 15/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.9418 - accuracy: 0.0833 - val_loss: 5.3968 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00015: loss improved from 4.96913 to 4.94182, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 16/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.9157 - accuracy: 0.0833 - val_loss: 5.3728 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00016: loss improved from 4.94182 to 4.91567, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 17/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.8911 - accuracy: 0.0833 - val_loss: 5.3513 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00017: loss improved from 4.91567 to 4.89113, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 18/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.8687 - accuracy: 0.0833 - val_loss: 5.3315 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00018: loss improved from 4.89113 to 4.86875, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 19/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.8482 - accuracy: 0.0833 - val_loss: 5.3131 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00019: loss improved from 4.86875 to 4.84824, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 20/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.8283 - accuracy: 0.0833 - val_loss: 5.2953 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00020: loss improved from 4.84824 to 4.82826, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 21/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.8091 - accuracy: 0.0833 - val_loss: 5.2781 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00021: loss improved from 4.82826 to 4.80910, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 22/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7905 - accuracy: 0.0833 - val_loss: 5.2617 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00022: loss improved from 4.80910 to 4.79049, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 23/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7725 - accuracy: 0.0833 - val_loss: 5.2466 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00023: loss improved from 4.79049 to 4.77254, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 24/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7556 - accuracy: 0.0833 - val_loss: 5.2325 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00024: loss improved from 4.77254 to 4.75557, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 25/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7395 - accuracy: 0.0833 - val_loss: 5.2190 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00025: loss improved from 4.75557 to 4.73947, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 26/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7241 - accuracy: 0.0833 - val_loss: 5.2067 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00026: loss improved from 4.73947 to 4.72415, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 27/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.7098 - accuracy: 0.0833 - val_loss: 5.1958 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00027: loss improved from 4.72415 to 4.70983, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 28/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6963 - accuracy: 0.0833 - val_loss: 5.1850 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00028: loss improved from 4.70983 to 4.69629, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 29/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6832 - accuracy: 0.0833 - val_loss: 5.1742 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00029: loss improved from 4.69629 to 4.68317, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 30/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6705 - accuracy: 0.0835 - val_loss: 5.1642 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00030: loss improved from 4.68317 to 4.67053, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 31/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6583 - accuracy: 0.0835 - val_loss: 5.1539 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00031: loss improved from 4.67053 to 4.65833, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 32/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6464 - accuracy: 0.0837 - val_loss: 5.1435 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00032: loss improved from 4.65833 to 4.64644, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 33/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6349 - accuracy: 0.0843 - val_loss: 5.1343 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00033: loss improved from 4.64644 to 4.63493, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 34/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6239 - accuracy: 0.0848 - val_loss: 5.1255 - val_accuracy: 0.0833\n",
      "\n",
      "Epoch 00034: loss improved from 4.63493 to 4.62389, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 35/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6133 - accuracy: 0.0857 - val_loss: 5.1159 - val_accuracy: 0.0845\n",
      "\n",
      "Epoch 00035: loss improved from 4.62389 to 4.61333, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 36/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.6027 - accuracy: 0.0861 - val_loss: 5.1066 - val_accuracy: 0.0845\n",
      "\n",
      "Epoch 00036: loss improved from 4.61333 to 4.60273, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 37/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5923 - accuracy: 0.0866 - val_loss: 5.0970 - val_accuracy: 0.0851\n",
      "\n",
      "Epoch 00037: loss improved from 4.60273 to 4.59233, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 38/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5821 - accuracy: 0.0871 - val_loss: 5.0884 - val_accuracy: 0.0851\n",
      "\n",
      "Epoch 00038: loss improved from 4.59233 to 4.58214, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 39/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5724 - accuracy: 0.0877 - val_loss: 5.0798 - val_accuracy: 0.0851\n",
      "\n",
      "Epoch 00039: loss improved from 4.58214 to 4.57235, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 40/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5628 - accuracy: 0.0887 - val_loss: 5.0720 - val_accuracy: 0.0862\n",
      "\n",
      "Epoch 00040: loss improved from 4.57235 to 4.56276, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 41/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5535 - accuracy: 0.0898 - val_loss: 5.0644 - val_accuracy: 0.0874\n",
      "\n",
      "Epoch 00041: loss improved from 4.56276 to 4.55346, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 42/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5445 - accuracy: 0.0907 - val_loss: 5.0561 - val_accuracy: 0.0880\n",
      "\n",
      "Epoch 00042: loss improved from 4.55346 to 4.54447, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 43/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5357 - accuracy: 0.0910 - val_loss: 5.0486 - val_accuracy: 0.0880\n",
      "\n",
      "Epoch 00043: loss improved from 4.54447 to 4.53566, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 44/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5270 - accuracy: 0.0913 - val_loss: 5.0416 - val_accuracy: 0.0880\n",
      "\n",
      "Epoch 00044: loss improved from 4.53566 to 4.52705, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 45/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5188 - accuracy: 0.0918 - val_loss: 5.0350 - val_accuracy: 0.0885\n",
      "\n",
      "Epoch 00045: loss improved from 4.52705 to 4.51878, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 46/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5107 - accuracy: 0.0923 - val_loss: 5.0282 - val_accuracy: 0.0885\n",
      "\n",
      "Epoch 00046: loss improved from 4.51878 to 4.51075, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 47/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.5029 - accuracy: 0.0953 - val_loss: 5.0206 - val_accuracy: 0.0914\n",
      "\n",
      "Epoch 00047: loss improved from 4.51075 to 4.50291, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 48/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4954 - accuracy: 0.0994 - val_loss: 5.0142 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00048: loss improved from 4.50291 to 4.49544, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 49/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4881 - accuracy: 0.0995 - val_loss: 5.0086 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00049: loss improved from 4.49544 to 4.48807, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 50/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4809 - accuracy: 0.0995 - val_loss: 5.0021 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00050: loss improved from 4.48807 to 4.48091, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 51/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4740 - accuracy: 0.0998 - val_loss: 4.9967 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00051: loss improved from 4.48091 to 4.47400, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 52/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4672 - accuracy: 0.1000 - val_loss: 4.9905 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00052: loss improved from 4.47400 to 4.46723, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 53/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4607 - accuracy: 0.1005 - val_loss: 4.9854 - val_accuracy: 0.0943\n",
      "\n",
      "Epoch 00053: loss improved from 4.46723 to 4.46073, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 54/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4543 - accuracy: 0.1009 - val_loss: 4.9802 - val_accuracy: 0.0943\n",
      "\n",
      "Epoch 00054: loss improved from 4.46073 to 4.45434, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 55/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4482 - accuracy: 0.1011 - val_loss: 4.9759 - val_accuracy: 0.0943\n",
      "\n",
      "Epoch 00055: loss improved from 4.45434 to 4.44816, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 56/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4420 - accuracy: 0.1011 - val_loss: 4.9714 - val_accuracy: 0.0943\n",
      "\n",
      "Epoch 00056: loss improved from 4.44816 to 4.44202, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 57/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4362 - accuracy: 0.1018 - val_loss: 4.9667 - val_accuracy: 0.0961\n",
      "\n",
      "Epoch 00057: loss improved from 4.44202 to 4.43618, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 58/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4304 - accuracy: 0.1023 - val_loss: 4.9616 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00058: loss improved from 4.43618 to 4.43044, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 59/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4249 - accuracy: 0.1033 - val_loss: 4.9563 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00059: loss improved from 4.43044 to 4.42486, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 60/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.4193 - accuracy: 0.1029 - val_loss: 4.9531 - val_accuracy: 0.0978\n",
      "\n",
      "Epoch 00060: loss improved from 4.42486 to 4.41929, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 61/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 4.4139 - accuracy: 0.1027 - val_loss: 4.9492 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00061: loss improved from 4.41929 to 4.41395, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 62/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 4.4087 - accuracy: 0.1031 - val_loss: 4.9449 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00062: loss improved from 4.41395 to 4.40867, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 63/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.4036 - accuracy: 0.1029 - val_loss: 4.9398 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00063: loss improved from 4.40867 to 4.40356, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 64/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3987 - accuracy: 0.1035 - val_loss: 4.9355 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00064: loss improved from 4.40356 to 4.39872, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 65/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3939 - accuracy: 0.1033 - val_loss: 4.9324 - val_accuracy: 0.0978\n",
      "\n",
      "Epoch 00065: loss improved from 4.39872 to 4.39388, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 66/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3893 - accuracy: 0.1032 - val_loss: 4.9293 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00066: loss improved from 4.39388 to 4.38926, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 67/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3848 - accuracy: 0.1032 - val_loss: 4.9255 - val_accuracy: 0.0990\n",
      "\n",
      "Epoch 00067: loss improved from 4.38926 to 4.38479, saving model to poem_rnn_3_layers.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3802 - accuracy: 0.1033 - val_loss: 4.9209 - val_accuracy: 0.0995\n",
      "\n",
      "Epoch 00068: loss improved from 4.38479 to 4.38022, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 69/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3758 - accuracy: 0.1035 - val_loss: 4.9185 - val_accuracy: 0.0995\n",
      "\n",
      "Epoch 00069: loss improved from 4.38022 to 4.37583, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 70/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3717 - accuracy: 0.1035 - val_loss: 4.9143 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00070: loss improved from 4.37583 to 4.37169, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 71/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3673 - accuracy: 0.1033 - val_loss: 4.9125 - val_accuracy: 0.0990\n",
      "\n",
      "Epoch 00071: loss improved from 4.37169 to 4.36726, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 72/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3631 - accuracy: 0.1033 - val_loss: 4.9092 - val_accuracy: 0.0990\n",
      "\n",
      "Epoch 00072: loss improved from 4.36726 to 4.36315, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 73/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3591 - accuracy: 0.1031 - val_loss: 4.9059 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00073: loss improved from 4.36315 to 4.35912, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 74/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3553 - accuracy: 0.1035 - val_loss: 4.9025 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00074: loss improved from 4.35912 to 4.35531, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 75/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3517 - accuracy: 0.1032 - val_loss: 4.8995 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00075: loss improved from 4.35531 to 4.35174, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 76/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3478 - accuracy: 0.1038 - val_loss: 4.8944 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00076: loss improved from 4.35174 to 4.34780, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 77/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3440 - accuracy: 0.1037 - val_loss: 4.8949 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00077: loss improved from 4.34780 to 4.34400, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 78/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3404 - accuracy: 0.1035 - val_loss: 4.8891 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00078: loss improved from 4.34400 to 4.34038, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 79/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3369 - accuracy: 0.1038 - val_loss: 4.8875 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00079: loss improved from 4.34038 to 4.33693, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 80/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3334 - accuracy: 0.1035 - val_loss: 4.8859 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00080: loss improved from 4.33693 to 4.33337, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 81/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3303 - accuracy: 0.1037 - val_loss: 4.8828 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00081: loss improved from 4.33337 to 4.33026, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 82/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3269 - accuracy: 0.1035 - val_loss: 4.8817 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00082: loss improved from 4.33026 to 4.32686, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 83/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3235 - accuracy: 0.1034 - val_loss: 4.8778 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00083: loss improved from 4.32686 to 4.32355, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 84/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3204 - accuracy: 0.1033 - val_loss: 4.8761 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00084: loss improved from 4.32355 to 4.32043, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 85/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3175 - accuracy: 0.1035 - val_loss: 4.8731 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00085: loss improved from 4.32043 to 4.31748, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 86/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3144 - accuracy: 0.1035 - val_loss: 4.8722 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00086: loss improved from 4.31748 to 4.31436, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 87/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3117 - accuracy: 0.1031 - val_loss: 4.8679 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00087: loss improved from 4.31436 to 4.31170, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 88/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3087 - accuracy: 0.1036 - val_loss: 4.8687 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00088: loss improved from 4.31170 to 4.30868, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 89/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3059 - accuracy: 0.1037 - val_loss: 4.8637 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00089: loss improved from 4.30868 to 4.30585, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 90/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3032 - accuracy: 0.1036 - val_loss: 4.8648 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00090: loss improved from 4.30585 to 4.30320, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 91/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.3005 - accuracy: 0.1033 - val_loss: 4.8605 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00091: loss improved from 4.30320 to 4.30048, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 92/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2977 - accuracy: 0.1037 - val_loss: 4.8589 - val_accuracy: 0.1007\n",
      "\n",
      "Epoch 00092: loss improved from 4.30048 to 4.29768, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 93/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2953 - accuracy: 0.1038 - val_loss: 4.8600 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00093: loss improved from 4.29768 to 4.29529, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 94/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2928 - accuracy: 0.1038 - val_loss: 4.8545 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00094: loss improved from 4.29529 to 4.29275, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 95/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2900 - accuracy: 0.1036 - val_loss: 4.8555 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00095: loss improved from 4.29275 to 4.29002, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 96/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2876 - accuracy: 0.1037 - val_loss: 4.8505 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00096: loss improved from 4.29002 to 4.28762, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 97/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2852 - accuracy: 0.1035 - val_loss: 4.8483 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00097: loss improved from 4.28762 to 4.28517, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 98/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2828 - accuracy: 0.1037 - val_loss: 4.8498 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00098: loss improved from 4.28517 to 4.28277, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 99/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2805 - accuracy: 0.1036 - val_loss: 4.8449 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00099: loss improved from 4.28277 to 4.28050, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 100/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2781 - accuracy: 0.1037 - val_loss: 4.8432 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00100: loss improved from 4.28050 to 4.27806, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 101/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2760 - accuracy: 0.1036 - val_loss: 4.8422 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00101: loss improved from 4.27806 to 4.27600, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 102/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2738 - accuracy: 0.1036 - val_loss: 4.8405 - val_accuracy: 0.1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00102: loss improved from 4.27600 to 4.27380, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 103/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2715 - accuracy: 0.1039 - val_loss: 4.8404 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00103: loss improved from 4.27380 to 4.27151, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 104/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2694 - accuracy: 0.1037 - val_loss: 4.8374 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00104: loss improved from 4.27151 to 4.26943, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 105/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2672 - accuracy: 0.1038 - val_loss: 4.8383 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00105: loss improved from 4.26943 to 4.26720, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 106/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2652 - accuracy: 0.1038 - val_loss: 4.8337 - val_accuracy: 0.1024\n",
      "\n",
      "Epoch 00106: loss improved from 4.26720 to 4.26517, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 107/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2634 - accuracy: 0.1040 - val_loss: 4.8366 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00107: loss improved from 4.26517 to 4.26338, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 108/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2612 - accuracy: 0.1040 - val_loss: 4.8298 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00108: loss improved from 4.26338 to 4.26116, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 109/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2593 - accuracy: 0.1038 - val_loss: 4.8308 - val_accuracy: 0.1024\n",
      "\n",
      "Epoch 00109: loss improved from 4.26116 to 4.25926, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 110/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2575 - accuracy: 0.1040 - val_loss: 4.8342 - val_accuracy: 0.0995\n",
      "\n",
      "Epoch 00110: loss improved from 4.25926 to 4.25753, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 111/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2558 - accuracy: 0.1038 - val_loss: 4.8247 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00111: loss improved from 4.25753 to 4.25580, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 112/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2536 - accuracy: 0.1038 - val_loss: 4.8250 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00112: loss improved from 4.25580 to 4.25359, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 113/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2519 - accuracy: 0.1040 - val_loss: 4.8314 - val_accuracy: 0.1001\n",
      "\n",
      "Epoch 00113: loss improved from 4.25359 to 4.25194, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 114/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2501 - accuracy: 0.1038 - val_loss: 4.8252 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00114: loss improved from 4.25194 to 4.25007, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 115/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2481 - accuracy: 0.1036 - val_loss: 4.8216 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00115: loss improved from 4.25007 to 4.24811, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 116/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2461 - accuracy: 0.1040 - val_loss: 4.8272 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00116: loss improved from 4.24811 to 4.24610, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 117/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2442 - accuracy: 0.1038 - val_loss: 4.8189 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00117: loss improved from 4.24610 to 4.24420, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 118/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2427 - accuracy: 0.1039 - val_loss: 4.8168 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00118: loss improved from 4.24420 to 4.24266, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 119/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2409 - accuracy: 0.1041 - val_loss: 4.8252 - val_accuracy: 0.1019\n",
      "\n",
      "Epoch 00119: loss improved from 4.24266 to 4.24091, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 120/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2396 - accuracy: 0.1035 - val_loss: 4.8129 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00120: loss improved from 4.24091 to 4.23963, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 121/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2376 - accuracy: 0.1044 - val_loss: 4.8188 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00121: loss improved from 4.23963 to 4.23755, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 122/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2363 - accuracy: 0.1042 - val_loss: 4.8263 - val_accuracy: 0.1013\n",
      "\n",
      "Epoch 00122: loss improved from 4.23755 to 4.23626, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 123/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2369 - accuracy: 0.1037 - val_loss: 4.8074 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00123: loss did not improve from 4.23626\n",
      "Epoch 124/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2326 - accuracy: 0.1044 - val_loss: 4.8167 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00124: loss improved from 4.23626 to 4.23263, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 125/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2307 - accuracy: 0.1042 - val_loss: 4.8127 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00125: loss improved from 4.23263 to 4.23072, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 126/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2292 - accuracy: 0.1041 - val_loss: 4.8125 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00126: loss improved from 4.23072 to 4.22923, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 127/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2275 - accuracy: 0.1039 - val_loss: 4.8094 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00127: loss improved from 4.22923 to 4.22747, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 128/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2263 - accuracy: 0.1046 - val_loss: 4.8210 - val_accuracy: 0.1019\n",
      "\n",
      "Epoch 00128: loss improved from 4.22747 to 4.22632, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 129/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2257 - accuracy: 0.1039 - val_loss: 4.8028 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00129: loss improved from 4.22632 to 4.22568, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 130/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2232 - accuracy: 0.1047 - val_loss: 4.8139 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00130: loss improved from 4.22568 to 4.22317, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 131/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2215 - accuracy: 0.1042 - val_loss: 4.8059 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00131: loss improved from 4.22317 to 4.22153, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 132/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2206 - accuracy: 0.1037 - val_loss: 4.8031 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00132: loss improved from 4.22153 to 4.22056, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 133/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2184 - accuracy: 0.1046 - val_loss: 4.8078 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00133: loss improved from 4.22056 to 4.21836, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 134/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2170 - accuracy: 0.1047 - val_loss: 4.8083 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00134: loss improved from 4.21836 to 4.21700, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 135/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2158 - accuracy: 0.1042 - val_loss: 4.8019 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00135: loss improved from 4.21700 to 4.21581, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 136/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2142 - accuracy: 0.1040 - val_loss: 4.8003 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00136: loss improved from 4.21581 to 4.21416, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 137/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2125 - accuracy: 0.1044 - val_loss: 4.8028 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00137: loss improved from 4.21416 to 4.21247, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 138/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2109 - accuracy: 0.1044 - val_loss: 4.8019 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00138: loss improved from 4.21247 to 4.21092, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 139/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2095 - accuracy: 0.1043 - val_loss: 4.7984 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00139: loss improved from 4.21092 to 4.20953, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 140/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2080 - accuracy: 0.1045 - val_loss: 4.8024 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00140: loss improved from 4.20953 to 4.20799, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 141/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2068 - accuracy: 0.1041 - val_loss: 4.7989 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00141: loss improved from 4.20799 to 4.20684, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 142/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2053 - accuracy: 0.1042 - val_loss: 4.7988 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00142: loss improved from 4.20684 to 4.20530, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 143/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2040 - accuracy: 0.1046 - val_loss: 4.7989 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00143: loss improved from 4.20530 to 4.20402, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 144/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2027 - accuracy: 0.1048 - val_loss: 4.7986 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00144: loss improved from 4.20402 to 4.20271, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 145/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2014 - accuracy: 0.1046 - val_loss: 4.7932 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00145: loss improved from 4.20271 to 4.20144, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 146/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.2000 - accuracy: 0.1042 - val_loss: 4.7928 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00146: loss improved from 4.20144 to 4.20001, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 147/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1991 - accuracy: 0.1044 - val_loss: 4.7967 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00147: loss improved from 4.20001 to 4.19909, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 148/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1975 - accuracy: 0.1049 - val_loss: 4.7991 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00148: loss improved from 4.19909 to 4.19752, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 149/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1972 - accuracy: 0.1041 - val_loss: 4.7911 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00149: loss improved from 4.19752 to 4.19724, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 150/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1950 - accuracy: 0.1043 - val_loss: 4.7911 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00150: loss improved from 4.19724 to 4.19502, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 151/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1934 - accuracy: 0.1045 - val_loss: 4.7900 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00151: loss improved from 4.19502 to 4.19343, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 152/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1922 - accuracy: 0.1049 - val_loss: 4.7909 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00152: loss improved from 4.19343 to 4.19216, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 153/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1911 - accuracy: 0.1050 - val_loss: 4.7947 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00153: loss improved from 4.19216 to 4.19110, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 154/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1899 - accuracy: 0.1047 - val_loss: 4.7937 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00154: loss improved from 4.19110 to 4.18985, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 155/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1886 - accuracy: 0.1046 - val_loss: 4.7883 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00155: loss improved from 4.18985 to 4.18865, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 156/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1873 - accuracy: 0.1044 - val_loss: 4.7882 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00156: loss improved from 4.18865 to 4.18726, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 157/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1859 - accuracy: 0.1047 - val_loss: 4.7880 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00157: loss improved from 4.18726 to 4.18594, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 158/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1845 - accuracy: 0.1047 - val_loss: 4.7882 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00158: loss improved from 4.18594 to 4.18455, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 159/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1834 - accuracy: 0.1050 - val_loss: 4.7855 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00159: loss improved from 4.18455 to 4.18345, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 160/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1827 - accuracy: 0.1051 - val_loss: 4.7821 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00160: loss improved from 4.18345 to 4.18268, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 161/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1818 - accuracy: 0.1052 - val_loss: 4.7923 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00161: loss improved from 4.18268 to 4.18181, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 162/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1802 - accuracy: 0.1049 - val_loss: 4.7878 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00162: loss improved from 4.18181 to 4.18022, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 163/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1792 - accuracy: 0.1045 - val_loss: 4.7823 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00163: loss improved from 4.18022 to 4.17922, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 164/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1775 - accuracy: 0.1049 - val_loss: 4.7815 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00164: loss improved from 4.17922 to 4.17751, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 165/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1764 - accuracy: 0.1052 - val_loss: 4.7843 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00165: loss improved from 4.17751 to 4.17636, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 166/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1750 - accuracy: 0.1054 - val_loss: 4.7829 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00166: loss improved from 4.17636 to 4.17500, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 167/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1739 - accuracy: 0.1054 - val_loss: 4.7806 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00167: loss improved from 4.17500 to 4.17395, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 168/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1729 - accuracy: 0.1055 - val_loss: 4.7800 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00168: loss improved from 4.17395 to 4.17288, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 169/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1720 - accuracy: 0.1051 - val_loss: 4.7888 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00169: loss improved from 4.17288 to 4.17196, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 170/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1708 - accuracy: 0.1054 - val_loss: 4.7821 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00170: loss improved from 4.17196 to 4.17080, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 171/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1694 - accuracy: 0.1054 - val_loss: 4.7803 - val_accuracy: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: loss improved from 4.17080 to 4.16938, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 172/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1684 - accuracy: 0.1053 - val_loss: 4.7788 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00172: loss improved from 4.16938 to 4.16842, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 173/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1672 - accuracy: 0.1051 - val_loss: 4.7770 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00173: loss improved from 4.16842 to 4.16717, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 174/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1660 - accuracy: 0.1057 - val_loss: 4.7807 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00174: loss improved from 4.16717 to 4.16603, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 175/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1648 - accuracy: 0.1053 - val_loss: 4.7782 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00175: loss improved from 4.16603 to 4.16481, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 176/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1637 - accuracy: 0.1055 - val_loss: 4.7814 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00176: loss improved from 4.16481 to 4.16366, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 177/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 4.1630 - accuracy: 0.1053 - val_loss: 4.7804 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00177: loss improved from 4.16366 to 4.16300, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 178/2000\n",
      "1292/1292 [==============================] - 3s 2ms/step - loss: 4.1618 - accuracy: 0.1052 - val_loss: 4.7781 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00178: loss improved from 4.16300 to 4.16175, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 179/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1605 - accuracy: 0.1054 - val_loss: 4.7735 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00179: loss improved from 4.16175 to 4.16053, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 180/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1594 - accuracy: 0.1053 - val_loss: 4.7815 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00180: loss improved from 4.16053 to 4.15944, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 181/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1585 - accuracy: 0.1051 - val_loss: 4.7733 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00181: loss improved from 4.15944 to 4.15855, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 182/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1574 - accuracy: 0.1054 - val_loss: 4.7758 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00182: loss improved from 4.15855 to 4.15737, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 183/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1572 - accuracy: 0.1053 - val_loss: 4.7761 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00183: loss improved from 4.15737 to 4.15715, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 184/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1562 - accuracy: 0.1050 - val_loss: 4.7781 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00184: loss improved from 4.15715 to 4.15624, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 185/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1549 - accuracy: 0.1053 - val_loss: 4.7767 - val_accuracy: 0.1047\n",
      "\n",
      "Epoch 00185: loss improved from 4.15624 to 4.15487, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 186/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1535 - accuracy: 0.1056 - val_loss: 4.7802 - val_accuracy: 0.1042\n",
      "\n",
      "Epoch 00186: loss improved from 4.15487 to 4.15346, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 187/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1524 - accuracy: 0.1054 - val_loss: 4.7717 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00187: loss improved from 4.15346 to 4.15242, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 188/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1510 - accuracy: 0.1051 - val_loss: 4.7701 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00188: loss improved from 4.15242 to 4.15098, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 189/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1506 - accuracy: 0.1053 - val_loss: 4.7745 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00189: loss improved from 4.15098 to 4.15064, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 190/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1492 - accuracy: 0.1053 - val_loss: 4.7753 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00190: loss improved from 4.15064 to 4.14915, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 191/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1483 - accuracy: 0.1054 - val_loss: 4.7679 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00191: loss improved from 4.14915 to 4.14826, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 192/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1476 - accuracy: 0.1048 - val_loss: 4.7726 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00192: loss improved from 4.14826 to 4.14763, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 193/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1458 - accuracy: 0.1056 - val_loss: 4.7720 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00193: loss improved from 4.14763 to 4.14579, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 194/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 4.1447 - accuracy: 0.1056 - val_loss: 4.7670 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00194: loss improved from 4.14579 to 4.14471, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 195/2000\n",
      "1292/1292 [==============================] - 3s 3ms/step - loss: 4.1440 - accuracy: 0.1054 - val_loss: 4.7667 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00195: loss improved from 4.14471 to 4.14396, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 196/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1427 - accuracy: 0.1051 - val_loss: 4.7694 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00196: loss improved from 4.14396 to 4.14268, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 197/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1417 - accuracy: 0.1059 - val_loss: 4.7695 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00197: loss improved from 4.14268 to 4.14169, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 198/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1406 - accuracy: 0.1057 - val_loss: 4.7682 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00198: loss improved from 4.14169 to 4.14061, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 199/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1399 - accuracy: 0.1053 - val_loss: 4.7668 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00199: loss improved from 4.14061 to 4.13988, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 200/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1387 - accuracy: 0.1057 - val_loss: 4.7647 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00200: loss improved from 4.13988 to 4.13871, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 201/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1378 - accuracy: 0.1054 - val_loss: 4.7648 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00201: loss improved from 4.13871 to 4.13785, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 202/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1378 - accuracy: 0.1053 - val_loss: 4.7680 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00202: loss improved from 4.13785 to 4.13780, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 203/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1360 - accuracy: 0.1057 - val_loss: 4.7717 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00203: loss improved from 4.13780 to 4.13601, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 204/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1350 - accuracy: 0.1055 - val_loss: 4.7722 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00204: loss improved from 4.13601 to 4.13504, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 205/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1345 - accuracy: 0.1056 - val_loss: 4.7718 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00205: loss improved from 4.13504 to 4.13454, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 206/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1330 - accuracy: 0.1058 - val_loss: 4.7662 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00206: loss improved from 4.13454 to 4.13301, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 207/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1321 - accuracy: 0.1057 - val_loss: 4.7717 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00207: loss improved from 4.13301 to 4.13206, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 208/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1320 - accuracy: 0.1055 - val_loss: 4.7654 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00208: loss improved from 4.13206 to 4.13204, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 209/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1303 - accuracy: 0.1059 - val_loss: 4.7629 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00209: loss improved from 4.13204 to 4.13028, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 210/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1293 - accuracy: 0.1060 - val_loss: 4.7636 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00210: loss improved from 4.13028 to 4.12933, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 211/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1284 - accuracy: 0.1065 - val_loss: 4.7701 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00211: loss improved from 4.12933 to 4.12839, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 212/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1292 - accuracy: 0.1058 - val_loss: 4.7606 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00212: loss did not improve from 4.12839\n",
      "Epoch 213/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1266 - accuracy: 0.1061 - val_loss: 4.7598 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00213: loss improved from 4.12839 to 4.12657, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 214/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1257 - accuracy: 0.1062 - val_loss: 4.7612 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00214: loss improved from 4.12657 to 4.12570, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 215/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1250 - accuracy: 0.1061 - val_loss: 4.7589 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00215: loss improved from 4.12570 to 4.12497, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 216/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1251 - accuracy: 0.1060 - val_loss: 4.7644 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00216: loss did not improve from 4.12497\n",
      "Epoch 217/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1237 - accuracy: 0.1062 - val_loss: 4.7612 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00217: loss improved from 4.12497 to 4.12367, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 218/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1222 - accuracy: 0.1061 - val_loss: 4.7608 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00218: loss improved from 4.12367 to 4.12218, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 219/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1209 - accuracy: 0.1067 - val_loss: 4.7590 - val_accuracy: 0.1065\n",
      "\n",
      "Epoch 00219: loss improved from 4.12218 to 4.12091, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 220/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1204 - accuracy: 0.1058 - val_loss: 4.7602 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00220: loss improved from 4.12091 to 4.12042, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 221/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1195 - accuracy: 0.1058 - val_loss: 4.7676 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00221: loss improved from 4.12042 to 4.11946, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 222/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1199 - accuracy: 0.1057 - val_loss: 4.7665 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00222: loss did not improve from 4.11946\n",
      "Epoch 223/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1204 - accuracy: 0.1058 - val_loss: 4.7604 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00223: loss did not improve from 4.11946\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 224/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1277 - accuracy: 0.1044 - val_loss: 4.8000 - val_accuracy: 0.1036\n",
      "\n",
      "Epoch 00224: loss did not improve from 4.11946\n",
      "Epoch 225/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1260 - accuracy: 0.1047 - val_loss: 4.7635 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00225: loss did not improve from 4.11946\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 226/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1175 - accuracy: 0.1063 - val_loss: 4.7535 - val_accuracy: 0.1076\n",
      "\n",
      "Epoch 00226: loss improved from 4.11946 to 4.11754, saving model to poem_rnn_3_layers.h5\n",
      "Epoch 227/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1223 - accuracy: 0.1053 - val_loss: 4.7535 - val_accuracy: 0.1076\n",
      "\n",
      "Epoch 00227: loss did not improve from 4.11754\n",
      "Epoch 228/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1220 - accuracy: 0.1053 - val_loss: 4.7534 - val_accuracy: 0.1071\n",
      "\n",
      "Epoch 00228: loss did not improve from 4.11754\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 229/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1199 - accuracy: 0.1057 - val_loss: 4.7538 - val_accuracy: 0.1065\n",
      "\n",
      "Epoch 00229: loss did not improve from 4.11754\n",
      "Epoch 230/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1190 - accuracy: 0.1057 - val_loss: 4.7540 - val_accuracy: 0.1065\n",
      "\n",
      "Epoch 00230: loss did not improve from 4.11754\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 231/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1186 - accuracy: 0.1058 - val_loss: 4.7541 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00231: loss did not improve from 4.11754\n",
      "Epoch 232/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1185 - accuracy: 0.1058 - val_loss: 4.7541 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00232: loss did not improve from 4.11754\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 233/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1184 - accuracy: 0.1058 - val_loss: 4.7541 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00233: loss did not improve from 4.11754\n",
      "Epoch 234/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1184 - accuracy: 0.1058 - val_loss: 4.7542 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00234: loss did not improve from 4.11754\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 235/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1184 - accuracy: 0.1058 - val_loss: 4.7542 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00235: loss did not improve from 4.11754\n",
      "Epoch 236/2000\n",
      "1292/1292 [==============================] - 4s 3ms/step - loss: 4.1184 - accuracy: 0.1058 - val_loss: 4.7542 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00236: loss did not improve from 4.11754\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 00236: early stopping\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "z = np.zeros((len(input_sequences), LATENT_DIM))\n",
    "r = model.fit(\n",
    "  [input_sequences, z, z],\n",
    "  one_hot_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT,\n",
    "  callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('poem_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sampling model\n",
    "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c])\n",
    "# now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse word2idx dictionary to get back words\n",
    "# during prediction\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "  # initial inputs\n",
    "  np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "  h = np.zeros((1, LATENT_DIM))\n",
    "  c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "  # so we know when to quit\n",
    "  eos = word2idx['<eos>']\n",
    "\n",
    "  # store the output here\n",
    "  output_sentence = []\n",
    "\n",
    "  for _ in range(max_sequence_length):\n",
    "    o, h, c = sampling_model.predict([np_input, h, c])\n",
    "\n",
    "    # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
    "    # idx = np.argmax(o[0,0])\n",
    "    probs = o[0,0]\n",
    "    if np.argmax(probs) == 0:\n",
    "      print(\"wtf\")\n",
    "    probs[0] = 0\n",
    "    probs /= probs.sum()\n",
    "    idx = np.random.choice(len(probs), p=probs)\n",
    "    if idx == eos:\n",
    "      break\n",
    "\n",
    "    # accuulate output\n",
    "    output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "    # make the next input into model\n",
    "    np_input[0,0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that caught to suggest better to the pecker-fretted\n",
      "and see to here thought since early\n"
     ]
    }
   ],
   "source": [
    "# generate a 4 line poem\n",
    "while True:\n",
    "    for _ in range(2):\n",
    "        print(sample_line())\n",
    "\n",
    "    ans = input(\"---generate another? [Y/n]---\")\n",
    "    if ans and ans[0].lower().startswith('n'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
